version: '3'
services:
  kafka:
    build: ./kafka
    ports:
      - 9092:9092 # Kafka port
  nifi:
    build: ./nifi
    environment:
      - SINGLE_USER_CREDENTIALS_USERNAME=admin
      - SINGLE_USER_CREDENTIALS_PASSWORD=ctsBtRBKHRAx69EqUghvvgEvjnaLjFEB
    ports:
      - 8443:8443
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop2.7.4-java8
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hive/hadoop-hive.env
    ports:
      - 50070:50070
      - 8020:8020
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    volumes:
      - datanode:/hadoop/dfs/data
    env_file:
      - ./hive/hadoop-hive.env
    environment:
      SERVICE_PRECONDITION: 'namenode:50070'
    ports:
      - 50075:50075
  hive-server:
    build: ./hive-server
    env_file:
      - ./hive/hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: 'jdbc:postgresql://hive-metastore/metastore'
      SERVICE_PRECONDITION: 'hive-metastore:9083'
    ports:
      - 10000:10000
  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hive/hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: 'namenode:50070 datanode:50075 hive-metastore-postgresql:5432'
    ports:
      - 9083:9083
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
  presto-coordinator:
    image: shawnzhu/prestodb:0.181
    ports:
      - 8889:8889
  spark:
    image: docker.io/bitnami/spark:3
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    ports:
      - 8080:8080
    volumes:
      - ./spark/jars/spark-sql-kafka-0-10_2.12-3.0.0.jar:/opt/bitnami/spark/jars/spark-sql-kafka-0-10_2.12-3.0.0.jar
      - ./spark/jars/spark-streaming_2.12-3.0.0.jar:/opt/bitnami/spark/jars/spark-streaming_2.12-3.0.0.jar
      - ./spark/jars/kafka-clients-3.0.0.jar:/opt/bitnami/spark/jars/kafka-clients-3.0.0.jar
      - ./spark/jars/spark-streaming-kafka-0-10_2.12-3.0.0.jar:/opt/bitnami/spark/jars/spark-streaming-kafka-0-10_2.12-3.0.0.jar
      - ./spark/jars/spark-token-provider-kafka-0-10_2.12-3.0.0.jar:/opt/bitnami/spark/jars/spark-token-provider-kafka-0-10_2.12-3.0.0.jar
      - ./spark/jars/commons-pool2-2.11.1.jar:/opt/bitnami/spark/jars/commons-pool2-2.11.1.jar
      - ./spark/jars/log4j-core-2.14.1.jar:/opt/bitnami/spark/jars/log4j-core-2.14.1.jar
      - ./spark/apps/logger.py:/opt/bitnami/spark/apps/logger.py
    command: spark-submit ./apps/logger.py
  spark-worker:
    image: docker.io/bitnami/spark:3
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ./spark/jars/spark-sql-kafka-0-10_2.12-3.0.0.jar:/opt/bitnami/spark/jars/spark-sql-kafka-0-10_2.12-3.0.0.jar
      - ./spark/jars/spark-streaming_2.12-3.0.0.jar:/opt/bitnami/spark/jars/spark-streaming_2.12-3.0.0.jar
      - ./spark/jars/kafka-clients-3.0.0.jar:/opt/bitnami/spark/jars/kafka-clients-3.0.0.jar
      - ./spark/jars/spark-streaming-kafka-0-10_2.12-3.0.0.jar:/opt/bitnami/spark/jars/spark-streaming-kafka-0-10_2.12-3.0.0.jar
      - ./spark/jars/spark-token-provider-kafka-0-10_2.12-3.0.0.jar:/opt/bitnami/spark/jars/spark-token-provider-kafka-0-10_2.12-3.0.0.jar
      - ./spark/jars/commons-pool2-2.11.1.jar:/opt/bitnami/spark/jars/commons-pool2-2.11.1.jar
      - ./spark/jars/log4j-core-2.14.1.jar:/opt/bitnami/spark/jars/log4j-core-2.14.1.jar

volumes:
  namenode:
  datanode:
